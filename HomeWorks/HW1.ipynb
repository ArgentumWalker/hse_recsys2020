{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Матричные факторизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной работе вам предстоит познакомиться с практической стороной матричных разложений.\n",
    "Работа поделена на 4 задания:\n",
    "1. Вам необходимо реализовать SVD разложения используя SGD на explicit данных\n",
    "2. Вам необходимо реализовать матричное разложения используя ALS на implicit данных\n",
    "3. Вам необходимо реализовать матричное разложения используя BPR(pair-wise loss) на implicit данных\n",
    "4. Вам необходимо реализовать матричное разложения используя WARP(list-wise loss) на implicit данных\n",
    "\n",
    "Мягкий дедлайн 28 Сентября (пишутся замечания, выставляется оценка, есть возможность исправить до жесткого дедлайна)\n",
    "\n",
    "Жесткий дедлайн 5 Октября (Итоговая проверка)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from lightfm.datasets import fetch_movielens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной работе мы будем работать с explicit датасетом movieLens, в котором представленны пары user_id movie_id и rating выставленный пользователем фильму\n",
    "\n",
    "Скачать датасет можно по ссылке https://grouplens.org/datasets/movielens/1m/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ml-1m/ratings.dat', delimiter='::', header=None, \n",
    "        names=['user_id', 'movie_id', 'rating', 'timestamp'], \n",
    "        usecols=['user_id', 'movie_id', 'rating'], engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_info = pd.read_csv('ml-1m/movies.dat', delimiter='::', header=None, \n",
    "        names=['movie_id', 'name', 'category'], engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicit данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1197</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2804</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating\n",
       "0        1      1193       5\n",
       "1        1       661       3\n",
       "2        1       914       3\n",
       "3        1      3408       4\n",
       "4        1      2355       5\n",
       "5        1      1197       3\n",
       "6        1      1287       5\n",
       "7        1      2804       5\n",
       "8        1       594       4\n",
       "9        1       919       4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы преобразовать текущий датасет в Implicit, давайте считать что позитивная оценка это оценка >=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "implicit_ratings = ratings.loc[(ratings['rating'] >= 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2804</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>595</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>938</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2398</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  movie_id  rating\n",
       "0         1      1193       5\n",
       "3         1      3408       4\n",
       "4         1      2355       5\n",
       "6         1      1287       5\n",
       "7         1      2804       5\n",
       "8         1       594       4\n",
       "9         1       919       4\n",
       "10        1       595       5\n",
       "11        1       938       4\n",
       "12        1      2398       4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit_ratings.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удобнее работать с sparse матричками, давайте преобразуем DataFrame в CSR матрицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = implicit_ratings[\"user_id\"]\n",
    "movies = implicit_ratings[\"movie_id\"]\n",
    "user_item = sp.coo_matrix((np.ones_like(users), (users, movies)))\n",
    "user_item_t_csr = user_item.T.tocsr()\n",
    "user_item_csr = user_item.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве примера воспользуемся ALS разложением из библиотеки implicit\n",
    "\n",
    "Зададим размерность латентного пространства равным 64, это же определяет размер user/item эмбедингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    }
   ],
   "source": [
    "model = implicit.als.AlternatingLeastSquares(factors=64, iterations=100, calculate_training_loss=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве loss здесь всеми любимый RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edcb7a0d3d7a419e9f54310c364fdab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(user_item_t_csr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим похожие фильмы по 1 movie_id = Истории игрушек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                name                      category\n",
       "0         1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1         2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2         3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3         4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4         5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_info.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similars = lambda item_id, model : [movie_info[movie_info[\"movie_id\"] == x[0]][\"name\"].to_string() \n",
    "                                        for x in model.similar_items(item_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, симилары действительно оказались симиларами.\n",
    "\n",
    "Качество симиларов часто является хорошим способом проверить качество алгоритмов.\n",
    "\n",
    "P.S. Если хочется поглубже разобраться в том как разные алгоритмы формируют разные латентные пространства, рекомендую загружать полученные вектора в tensorBoard и смотреть на сформированное пространство"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0    Toy Story (1995)',\n",
       " '3045    Toy Story 2 (1999)',\n",
       " \"2286    Bug's Life, A (1998)\",\n",
       " '33    Babe (1995)',\n",
       " '584    Aladdin (1992)',\n",
       " '2315    Babe: Pig in the City (1998)',\n",
       " '360    Lion King, The (1994)',\n",
       " '1526    Hercules (1997)',\n",
       " '1838    Mulan (1998)',\n",
       " '2618    Tarzan (1999)']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similars(1, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте теперь построим рекомендации для юзеров\n",
    "\n",
    "Как мы видим юзеру нравится фантастика, значит и в рекомендациях ожидаем увидеть фантастику"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_user_history = lambda user_id, implicit_ratings : [movie_info[movie_info[\"movie_id\"] == x][\"name\"].to_string() \n",
    "                                            for x in implicit_ratings[implicit_ratings[\"user_id\"] == user_id][\"movie_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3399    Hustler, The (1961)',\n",
       " '2882    Fistful of Dollars, A (1964)',\n",
       " '1196    Alien (1979)',\n",
       " '1023    Die Hard (1988)',\n",
       " '257    Star Wars: Episode IV - A New Hope (1977)',\n",
       " '1959    Saving Private Ryan (1998)',\n",
       " '476    Jurassic Park (1993)',\n",
       " '1180    Raiders of the Lost Ark (1981)',\n",
       " '1885    Rocky (1976)',\n",
       " '1081    E.T. the Extra-Terrestrial (1982)',\n",
       " '3349    Thelma & Louise (1991)',\n",
       " '3633    Mad Max (1979)',\n",
       " '2297    King Kong (1933)',\n",
       " '1366    Jaws (1975)',\n",
       " '1183    Good, The Bad and The Ugly, The (1966)',\n",
       " '2623    Run Lola Run (Lola rennt) (1998)',\n",
       " '2878    Goldfinger (1964)',\n",
       " '1220    Terminator, The (1984)']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_user_history(4, implicit_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось! \n",
    "\n",
    "Мы действительно порекомендовали пользователю фантастику и боевики, более того встречаются продолжения тех фильмов, которые он высоко оценил"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations = lambda user_id, model : [movie_info[movie_info[\"movie_id\"] == x[0]][\"name\"].to_string() \n",
    "                                               for x in model.recommend(user_id, user_item_csr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['585    Terminator 2: Judgment Day (1991)',\n",
       " '1271    Indiana Jones and the Last Crusade (1989)',\n",
       " '2502    Matrix, The (1999)',\n",
       " '1182    Aliens (1986)',\n",
       " '1284    Butch Cassidy and the Sundance Kid (1969)',\n",
       " '1178    Star Wars: Episode V - The Empire Strikes Back...',\n",
       " '3402    Close Encounters of the Third Kind (1977)',\n",
       " '847    Godfather, The (1972)',\n",
       " '2460    Planet of the Apes (1968)',\n",
       " '1179    Princess Bride, The (1987)']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(4, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь ваша очередь реализовать самые популярные алгоритмы матричных разложений\n",
    "\n",
    "Что будет оцениваться:\n",
    "1. Корректность алгоритма\n",
    "2. Качество получившихся симиларов\n",
    "3. Качество итоговых рекомендаций для юзера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from sklearn.neighbors import KDTree \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1. Не использую готовые решения, реализовать SVD разложение используя SGD на explicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratings_to_tensor(ratings, unique_users=None, unique_movies=None):\n",
    "    if unique_users is None:\n",
    "        unique_users = ratings.user_id.unique()\n",
    "    if unique_movies is None:\n",
    "        unique_movies = ratings.movie_id.unique()\n",
    "    user2id = dict([(u, i) for i, u in enumerate(unique_users)])\n",
    "    movie2id = dict([(m, i) for i, m in enumerate(unique_movies)])\n",
    "    mask = torch.zeros(len(unique_users), len(unique_movies))\n",
    "    mat = torch.zeros(len(unique_users), len(unique_movies))\n",
    "    for u, m, r in zip(ratings.user_id, ratings.movie_id, ratings.rating):\n",
    "        mat[user2id[u]][movie2id[m]] = float(r)\n",
    "        mask[user2id[u]][movie2id[m]] = 1\n",
    "    mask = mask.bool()\n",
    "    return mat, mask, unique_users, unique_movies\n",
    "\n",
    "ratings_tensor, rt_mask, u_users, u_movies = ratings_to_tensor(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 3., 3.,  ..., 0., 0., 0.],\n",
       "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 3., 4.,  ..., 0., 0., 0.],\n",
       "        [4., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecSys:\n",
    "    def __init__(self, users, items):\n",
    "        self.user2id = dict([(u, i) for i, u in enumerate(users)])\n",
    "        self.item2id = dict([(m, i) for i, m in enumerate(items)])\n",
    "        self.users = users\n",
    "        self.items = items\n",
    "        self.items_tree = None\n",
    "        \n",
    "    def get_items_repr(self):\n",
    "        raise NotImplemented\n",
    "    \n",
    "    def compute_score(self):\n",
    "        raise NotImplemented\n",
    "        \n",
    "    def _build_trees(self):\n",
    "        self.items_tree = KDTree(self.get_items_repr())\n",
    "    \n",
    "    def recommend(self, user_id, _, k=20):\n",
    "        u = self.user2id[user_id]\n",
    "        r = self.compute_score()[u]\n",
    "        idx = list(reversed(np.argsort(r)))[:k]\n",
    "        result_idx = [self.items[i] for i in idx]\n",
    "        return list(zip(result_idx, r[idx]))\n",
    "        \n",
    "    def similar_items(self, item_id, k=20):\n",
    "        i = [self.get_items_repr()[self.item2id[item_id]]]\n",
    "        d, idx = self.items_tree.query(i, k, return_distance=True)\n",
    "        true_idx = [self.items[i] for i in idx[0]]\n",
    "        return list(zip(true_idx, d[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55fdfaff65cb4816bf43925cd61a596f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class SVD(RecSys):\n",
    "    def __init__(self, users, items, hidden_size=64):\n",
    "        super().__init__(users, items)\n",
    "        self.U = torch.rand(len(users), hidden_size) / hidden_size**0.5\n",
    "        self.V = torch.rand(hidden_size, len(items)) / hidden_size**0.5\n",
    "        \n",
    "    def __call__(self):\n",
    "        return self.U.matmul(self.V)\n",
    "    \n",
    "    def get_items_repr(self):\n",
    "        return self.V.transpose(0, 1).cpu().numpy()\n",
    "    \n",
    "    def compute_score(self):\n",
    "        return self().cpu().numpy()\n",
    "\n",
    "    def fit(self, x, x_mask, iterations=500, lr=100.0, weight_decay=1e-2, masked=False):\n",
    "        # It can be done way more effectively with good dataloader, batches and torch.optim, \n",
    "        # but ready solutions are forbidden :(\n",
    "        t = tqdm(range(iterations))\n",
    "        ratings_count = x_mask.int().sum().item()\n",
    "        u_count = torch.ones_like(self.U).sum() # Well, this is obviously not optimal\n",
    "        v_count = torch.ones_like(self.V).sum()\n",
    "        for i in t:\n",
    "            eps = (self() - x)\n",
    "            eps[x_mask.logical_not()] = 0 # Do not update over NaN items\n",
    "            u_grad = eps.matmul(self.V.transpose(0, 1)) / ratings_count + weight_decay * self.U / u_count\n",
    "            v_grad = self.U.transpose(0, 1).matmul(eps) / ratings_count + weight_decay * self.V / v_count\n",
    "            self.U -= lr * u_grad\n",
    "            self.V -= lr * v_grad\n",
    "            mse = ((self() - x) ** 2)[x_mask].sum() / ratings_count\n",
    "            t.set_postfix_str(f\"MSE: {mse:.4f} | L2 Norm: {(self.U**2).mean():.4f}\")\n",
    "        self._build_trees()\n",
    "\n",
    "svd = SVD(u_users, u_movies, 64)\n",
    "svd.fit(ratings_tensor, rt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 3., 3.,  ..., 0., 0., 0.],\n",
       "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 3., 4.,  ..., 0., 0., 0.],\n",
       "        [4., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.5521, 3.5784, 4.4002,  ..., 0.8559, 1.3589, 1.2168],\n",
       "        [4.1298, 3.1852, 4.1064,  ..., 0.7769, 1.2532, 1.0745],\n",
       "        [4.3105, 3.4834, 4.2767,  ..., 0.8542, 1.3389, 1.1983],\n",
       "        ...,\n",
       "        [4.0917, 3.2196, 3.9727,  ..., 0.7628, 1.2173, 1.0802],\n",
       "        [4.1377, 3.2927, 4.0795,  ..., 0.7865, 1.2833, 1.1152],\n",
       "        [4.4151, 3.2846, 3.7495,  ..., 0.7336, 1.2077, 1.0879]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2836    Sanjuro (1962)',\n",
       " '1950    Seven Samurai (The Magnificent Seven) (Shichin...',\n",
       " '49    Usual Suspects, The (1995)',\n",
       " '315    Shawshank Redemption, The (1994)',\n",
       " '847    Godfather, The (1972)',\n",
       " '1189    To Kill a Mockingbird (1962)',\n",
       " '1132    Wrong Trousers, The (1993)',\n",
       " \"523    Schindler's List (1993)\",\n",
       " '1162    Paths of Glory (1957)',\n",
       " '735    Close Shave, A (1995)',\n",
       " '910    Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)',\n",
       " '740    Dr. Strangelove or: How I Learned to Stop Worr...',\n",
       " '892    Rear Window (1954)',\n",
       " \"1176    One Flew Over the Cuckoo's Nest (1975)\",\n",
       " '2953    General, The (1927)',\n",
       " '1194    Third Man, The (1949)',\n",
       " '901    Maltese Falcon, The (1941)',\n",
       " '1186    Lawrence of Arabia (1962)',\n",
       " '2961    Yojimbo (1961)',\n",
       " '662    Pather Panchali (1955)']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(4, svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0    Toy Story (1995)',\n",
       " '584    Aladdin (1992)',\n",
       " \"941    It's a Wonderful Life (1946)\",\n",
       " '2012    Little Mermaid, The (1989)',\n",
       " '3045    Toy Story 2 (1999)',\n",
       " '148    Apollo 13 (1995)',\n",
       " '591    Beauty and the Beast (1991)',\n",
       " '1222    Glory (1989)',\n",
       " '3291    Hoosiers (1986)',\n",
       " '2728    Big (1988)',\n",
       " '2970    Trading Places (1983)',\n",
       " '1212    Right Stuff, The (1983)',\n",
       " '922    Father of the Bride (1950)',\n",
       " '2125    Untouchables, The (1987)',\n",
       " '1375    Sneakers (1992)',\n",
       " '1267    Ben-Hur (1959)',\n",
       " '3090    Fantasia 2000 (1999)',\n",
       " '1215    Sting, The (1973)',\n",
       " '2329    Miracle on 34th Street (1947)',\n",
       " '1282    Field of Dreams (1989)']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similars(1, svd)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2. Не использую готовые решения, реализовать матричное разложение используя ALS на implicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_ratings_tensor, i_rt_mask, _, _ = ratings_to_tensor(implicit_ratings, u_users, u_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c0a7b457ee4eda9f9f1f171808e61d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class ALS(RecSys):\n",
    "    def __init__(self, users, items, hidden_size=64):\n",
    "        super().__init__(users, items)\n",
    "        self.U = torch.rand(len(users), hidden_size) / hidden_size**0.5\n",
    "        self.V = torch.rand(hidden_size, len(items)) / hidden_size**0.5\n",
    "        self.v_bias = torch.zeros(len(items))\n",
    "        self.u_bias = torch.zeros(len(users))\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "    def __call__(self):\n",
    "        return self.U.matmul(self.V)\n",
    "    \n",
    "    def get_items_repr(self):\n",
    "        return self.V.transpose(0, 1).cpu().numpy()\n",
    "    \n",
    "    def compute_score(self):\n",
    "        return self().cpu().numpy()\n",
    "\n",
    "    def fit(self, x, x_mask, iterations=8, nonzero_coef=10, weight_decay=0.01):\n",
    "        t = tqdm(range(iterations))\n",
    "        ratings_count = x_mask.int().sum().item() \n",
    "        u_count = torch.ones_like(self.U).sum() # Well, this is obviously not optimal\n",
    "        v_count = torch.ones_like(self.V).sum()\n",
    "        x = x.clone()\n",
    "        x[x_mask] = 1\n",
    "        w = torch.ones_like(x)\n",
    "        w[x_mask] += nonzero_coef * x[x_mask].abs()\n",
    "        w /= w.max()\n",
    "        x_target = w * x\n",
    "        for _ in t:\n",
    "            # Step 1: User representations\n",
    "            for u in range(len(self.U)):\n",
    "                Vb = torch.cat([self.V, torch.ones(1, self.V.size(1))], dim=0)\n",
    "                VCV = Vb.matmul(w[u][:, None] * Vb.transpose(0, 1))\n",
    "                VCV = VCV + weight_decay * torch.eye(self.hidden_size + 1)\n",
    "                VCV = torch.inverse(VCV)\n",
    "                Ub = VCV.matmul(Vb).matmul((w[u] * (x[u] - self.v_bias)))\n",
    "                self.U[u] = Ub[:-1]\n",
    "                self.u_bias[u] = Ub[-1]\n",
    "            # Step 2: Item representations\n",
    "            for i in range(self.V.size(1)):\n",
    "                Ub  = torch.cat([self.U, torch.ones(self.U.size(0), 1)], dim=1)\n",
    "                UCU = Ub.transpose(0, 1).matmul(w[:, i][:, None] * Ub)\n",
    "                UCU = UCU + weight_decay * torch.eye(self.hidden_size + 1)\n",
    "                UCU = torch.inverse(UCU)\n",
    "                Vb = UCU.matmul(Ub.transpose(0, 1)).matmul((w[:, i] * (x[:, i] - self.u_bias)))\n",
    "                self.V[:, i] = Vb[:-1]\n",
    "                self.v_bias[i] = Vb[-1]\n",
    "            # Log\n",
    "            uv = self()\n",
    "            mse = ((uv + self.u_bias[:, None].expand_as(uv)  + self.v_bias[None, :].expand_as(uv) - x) ** 2)[x_mask].sum() / ratings_count\n",
    "            t.set_postfix_str(f\"MSE: {mse:.4f} | L2 Norm: {(self.U**2).mean():.4f}\")\n",
    "        self._build_trees()\n",
    "\n",
    "als = ALS(u_users, u_movies, 64)\n",
    "als.fit(i_ratings_tensor, i_rt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 4.,  ..., 0., 0., 0.],\n",
       "        [4., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_ratings_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4470,  0.4080,  0.3294,  ..., -0.0299,  0.0041, -0.0436],\n",
       "        [ 0.6316, -0.0642,  0.2251,  ..., -0.0521, -0.0523, -0.0583],\n",
       "        [-0.0155, -0.2933, -0.1961,  ..., -0.0250, -0.0116, -0.0224],\n",
       "        ...,\n",
       "        [ 0.0257, -0.1270,  0.1280,  ..., -0.0252, -0.0477, -0.0299],\n",
       "        [ 0.2652,  0.3126,  0.7765,  ..., -0.0045,  0.0022, -0.0127],\n",
       "        [ 0.3902, -0.2303,  0.0875,  ..., -0.2369, -0.2677, -0.2475]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1366    Jaws (1975)',\n",
       " '1885    Rocky (1976)',\n",
       " '2878    Goldfinger (1964)',\n",
       " '1183    Good, The Bad and The Ugly, The (1966)',\n",
       " '1220    Terminator, The (1984)',\n",
       " '1023    Die Hard (1988)',\n",
       " '2882    Fistful of Dollars, A (1964)',\n",
       " '2297    King Kong (1933)',\n",
       " '3633    Mad Max (1979)',\n",
       " '3349    Thelma & Louise (1991)',\n",
       " '1196    Alien (1979)',\n",
       " '3634    Mad Max 2 (a.k.a. The Road Warrior) (1981)',\n",
       " '1271    Indiana Jones and the Last Crusade (1989)',\n",
       " '453    Fugitive, The (1993)',\n",
       " '2875    Dirty Dozen, The (1967)',\n",
       " '1884    French Connection, The (1971)',\n",
       " '1568    Hunt for Red October, The (1990)',\n",
       " '1182    Aliens (1986)',\n",
       " '585    Terminator 2: Judgment Day (1991)',\n",
       " '2125    Untouchables, The (1987)']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(4, als)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0    Toy Story (1995)',\n",
       " '3045    Toy Story 2 (1999)',\n",
       " '1245    Groundhog Day (1993)',\n",
       " \"2286    Bug's Life, A (1998)\",\n",
       " '2252    Pleasantville (1998)',\n",
       " '584    Aladdin (1992)',\n",
       " \"1854    There's Something About Mary (1998)\",\n",
       " '360    Lion King, The (1994)',\n",
       " '591    Beauty and the Beast (1991)',\n",
       " '33    Babe (1995)',\n",
       " '2327    Shakespeare in Love (1998)',\n",
       " '1595    Full Monty, The (1997)',\n",
       " '2741    Perfect Blue (1997)',\n",
       " '1596    Indian Summer (a.k.a. Alive & Kicking) (1996)',\n",
       " '634    Girl 6 (1996)',\n",
       " '1811    Lawn Dogs (1997)',\n",
       " '990    Extreme Measures (1996)',\n",
       " '1445    Best Men (1997)',\n",
       " '1838    Mulan (1998)',\n",
       " '1812    Quest for Camelot (1998)']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similars(1, als)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3. Не использую готовые решения, реализовать матричное разложение BPR на implicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19833da9e734e92a7c6857e0cbec106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6040.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-9dacc2bb0e6c>:5: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  user2positives.append((x[u] != 0).nonzero().view(-1).tolist())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def build_positives_and_negatives(x):\n",
    "    user2positives = []\n",
    "    user2negatives = []\n",
    "    for u in tqdm(range(len(x))):\n",
    "        user2positives.append((x[u] != 0).nonzero().view(-1).tolist())\n",
    "        user2negatives.append((x[u] == 0).nonzero().view(-1).tolist())\n",
    "    return user2positives, user2negatives\n",
    "\n",
    "u2p, u2n = build_positives_and_negatives(i_rt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1785198aa2d470d87b022b77e33b29d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class BPR(RecSys):\n",
    "    def __init__(self, users, items, hidden_size=64):\n",
    "        super().__init__(users, items)\n",
    "        self.U = torch.rand(len(users), hidden_size) / hidden_size**0.5\n",
    "        self.V = torch.rand(hidden_size, len(items)) / hidden_size**0.5\n",
    "        \n",
    "    def __call__(self):\n",
    "        return self.U.matmul(self.V)\n",
    "    \n",
    "    def get_items_repr(self):\n",
    "        return self.V.transpose(0, 1).cpu().numpy()\n",
    "    \n",
    "    def compute_score(self):\n",
    "        return self().cpu().numpy()\n",
    "\n",
    "    def fit(self, user2positives, user2negatives, iterations=500, acc_grad=16, lr=0.1, weight_decay=1e-2, masked=False):\n",
    "        # It can be done way more effectively with good dataloader, batches and torch.optim, \n",
    "        # but ready solutions are forbidden :(\n",
    "        \n",
    "        t = tqdm(range(iterations))\n",
    "        for i in t:\n",
    "            u_grad = acc_grad * weight_decay * self.U\n",
    "            v_grad = acc_grad * weight_decay * self.V\n",
    "            mean_delta = 0.\n",
    "            x = self()\n",
    "            for _ in range(acc_grad):\n",
    "                # Build a batch\n",
    "                positives = []\n",
    "                negatives = []\n",
    "                pos_mask = []\n",
    "                neg_mask = []\n",
    "                for u in range(len(user2positives)):\n",
    "                    if len(user2positives[u]) != 0:\n",
    "                        pos_mask.append(1)\n",
    "                        positives.append(user2positives[u][random.randint(0, len(user2positives[u]) - 1)])\n",
    "                    else:\n",
    "                        pos_mask.append(0)\n",
    "                        positives.append(0)\n",
    "                    if len(user2negatives[u]) != 0:\n",
    "                        neg_mask.append(1)\n",
    "                        negatives.append(user2negatives[u][random.randint(0, len(user2negatives[u]) - 1)])\n",
    "                    else:\n",
    "                        neg_mask.append(0)\n",
    "                        negatives.append(0)\n",
    "                positives = torch.tensor(positives)\n",
    "                negatives = torch.tensor(negatives)\n",
    "                pos_mask = torch.tensor(pos_mask).float()\n",
    "                neg_mask = torch.tensor(neg_mask).float()\n",
    "\n",
    "                # Compute gradient\n",
    "                delta = x.gather(1, positives.unsqueeze(1)) - x.gather(1, negatives.unsqueeze(1)) \n",
    "                mean_delta += delta.mean()\n",
    "                delta = torch.exp(-delta).view(-1)\n",
    "                delta = -delta / (1 + delta)\n",
    "                v_positives = self.V[:, positives].transpose(0, 1)\n",
    "                v_negatives = self.V[:, negatives].transpose(0, 1)\n",
    "                u_grad += delta[:, None] * (pos_mask[:, None] * v_positives - neg_mask[:, None] * v_negatives)\n",
    "\n",
    "                v_grad[:, positives] += ((pos_mask * delta)[:, None] * self.U).transpose(0, 1)\n",
    "                v_grad[:, negatives] -= ((neg_mask * delta)[:, None] * self.U).transpose(0, 1)\n",
    "            self.U -= lr * u_grad / acc_grad\n",
    "            self.V -= lr * v_grad / acc_grad\n",
    "            mean_delta /= acc_grad\n",
    "            t.set_postfix_str(f\"Avg delta: {mean_delta:4f} | Avg nabla V: {v_grad.abs().mean():.4f} | L2 Norm: {(self.U**2).mean():.4f}\")\n",
    "        self._build_trees()\n",
    "\n",
    "bpr = BPR(u_users, u_movies, 64)\n",
    "bpr.fit(u2p, u2n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 4.,  ..., 0., 0., 0.],\n",
       "        [4., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_ratings_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-17.2365, -16.1310, -15.5061,  ..., -19.3519, -19.2534, -19.1541],\n",
       "        [-17.2136, -18.1117, -17.2744,  ..., -19.8719, -19.8321, -19.7105],\n",
       "        [-18.6773, -18.0149, -18.2975,  ..., -19.9499, -19.9098, -19.8093],\n",
       "        ...,\n",
       "        [-13.5889, -13.2168, -11.9447,  ..., -15.0270, -14.9637, -14.7568],\n",
       "        [-14.0932, -13.9040, -11.8441,  ..., -16.4136, -16.3436, -16.2744],\n",
       "        [-13.7055, -15.5661, -15.0003,  ..., -16.9317, -16.9425, -16.7352]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1196    Alien (1979)',\n",
       " '257    Star Wars: Episode IV - A New Hope (1977)',\n",
       " '1178    Star Wars: Episode V - The Empire Strikes Back...',\n",
       " '1220    Terminator, The (1984)',\n",
       " '1182    Aliens (1986)',\n",
       " '2878    Goldfinger (1964)',\n",
       " '1183    Good, The Bad and The Ugly, The (1966)',\n",
       " '1023    Die Hard (1988)',\n",
       " '1366    Jaws (1975)',\n",
       " '1180    Raiders of the Lost Ark (1981)',\n",
       " '2297    King Kong (1933)',\n",
       " '1204    Full Metal Jacket (1987)',\n",
       " '2879    From Russia with Love (1963)',\n",
       " '1203    Godfather: Part II, The (1974)',\n",
       " '585    Terminator 2: Judgment Day (1991)',\n",
       " '1959    Saving Private Ryan (1998)',\n",
       " '2875    Dirty Dozen, The (1967)',\n",
       " '2882    Fistful of Dollars, A (1964)',\n",
       " '1885    Rocky (1976)',\n",
       " '2460    Planet of the Apes (1968)']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(4, bpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0    Toy Story (1995)',\n",
       " '33    Babe (1995)',\n",
       " '1245    Groundhog Day (1993)',\n",
       " '2315    Babe: Pig in the City (1998)',\n",
       " '3045    Toy Story 2 (1999)',\n",
       " '565    Little Big League (1994)',\n",
       " '591    Beauty and the Beast (1991)',\n",
       " \"2430    God Said 'Ha!' (1998)\",\n",
       " '2021    Rescuers, The (1977)',\n",
       " '584    Aladdin (1992)',\n",
       " '1600    Rocket Man (1997)',\n",
       " '1850    Madeline (1998)',\n",
       " '179    Mighty Morphin Power Rangers: The Movie (1995)',\n",
       " '2014    Muppet Christmas Carol, The (1992)',\n",
       " '1702    Shooting Fish (1997)',\n",
       " '2067    Nutty Professor, The (1963)',\n",
       " '711    Wallace & Gromit: The Best of Aardman Animatio...',\n",
       " '2807    Thumbelina (1994)',\n",
       " '1081    E.T. the Extra-Terrestrial (1982)',\n",
       " '2226    Impostors, The (1998)']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similars(1, bpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4. Не использую готовые решения, реализовать матричное разложение WARP на implicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6de45c4783f4dca93fc836af8c25ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class WARP(RecSys):\n",
    "    def __init__(self, users, items, hidden_size=64):\n",
    "        super().__init__(users, items)\n",
    "        self.U = torch.rand(len(users), hidden_size) / hidden_size**0.5\n",
    "        self.V = torch.rand(hidden_size, len(items)) / hidden_size**0.5\n",
    "        \n",
    "    def __call__(self):\n",
    "        return self.U.matmul(self.V)\n",
    "    \n",
    "    def get_items_repr(self):\n",
    "        return self.V.transpose(0, 1).cpu().numpy()\n",
    "    \n",
    "    def compute_score(self):\n",
    "        return self().cpu().numpy()\n",
    "\n",
    "    def fit(self, user2positives, user2negatives, iterations=50, samples=16, acc_grad=8, \n",
    "            lr=0.1, weight_decay=1e-3, masked=False):\n",
    "        # It can be done way more effectively with good dataloader, batches and torch.optim, \n",
    "        # but ready solutions are forbidden :(\n",
    "        \n",
    "        t = tqdm(range(iterations))\n",
    "        for i in t:\n",
    "            u_grad = acc_grad * weight_decay * self.U\n",
    "            v_grad = acc_grad * weight_decay * self.V\n",
    "            mean_delta = 0.\n",
    "            x = self()\n",
    "            for k in range(acc_grad):\n",
    "                # Build a batch\n",
    "                positives = []\n",
    "                negatives = []\n",
    "                ranking_weight = []\n",
    "                pos_mask = []\n",
    "                neg_mask = []\n",
    "                for u in range(len(user2positives)):\n",
    "                    if len(user2positives[u]) != 0:\n",
    "                        pos = user2positives[u][random.randint(0, len(user2positives[u]) - 1)]\n",
    "                        pos_mask.append(1)\n",
    "                        positives.append(pos)\n",
    "                        # Finding all high-ranked negatives is very slow, so we sample and estimate rank\n",
    "                        choosen_negatives = random.sample(user2negatives[u], min(samples, len(user2negatives[u])))\n",
    "                        bad_negatives = (x[u, choosen_negatives] > x[u, pos]).nonzero()\n",
    "                        if len(bad_negatives) != 0:\n",
    "                            neg_mask.append(1)\n",
    "                            neg = bad_negatives[random.randint(0, len(bad_negatives) - 1)]\n",
    "                            negatives.append(choosen_negatives[neg])\n",
    "                            #ranking_weight.append(np.log(len(bad_negatives)))\n",
    "                            ranking_weight.append(np.log((x.size(1) - 1) * len(bad_negatives) / len(choosen_negatives)))\n",
    "                        else:\n",
    "                            neg_mask.append(0)\n",
    "                            negatives.append(0)\n",
    "                            ranking_weight.append(0)\n",
    "                    else:\n",
    "                        pos_mask.append(0)\n",
    "                        positives.append(0)\n",
    "                        neg_mask.append(1)\n",
    "                        ranking_weight.append(1)\n",
    "                        negatives.append(user2negatives[u][random.randint(0, len(user2negatives[u]) - 1)])\n",
    "\n",
    "                positives = torch.tensor(positives)\n",
    "                negatives = torch.tensor(negatives)\n",
    "                pos_mask = torch.tensor(pos_mask).float()\n",
    "                neg_mask = torch.tensor(neg_mask).float()\n",
    "                ranking_weight = torch.tensor(ranking_weight)\n",
    "                \n",
    "                # Compute gradient\n",
    "                mean_delta += (x.gather(1, positives.unsqueeze(1)) - x.gather(1, negatives.unsqueeze(1))).mean()\n",
    "                ranking_weight /= ranking_weight.mean() # Fixing stability issues\n",
    "                v_positives = self.V[:, positives].transpose(0, 1)\n",
    "                v_negatives = self.V[:, negatives].transpose(0, 1)\n",
    "                u_grad += ranking_weight[:, None] * (neg_mask[:, None] * v_negatives - pos_mask[:, None] * v_positives)\n",
    "\n",
    "                v_grad[:, positives] -= ((pos_mask * ranking_weight)[:, None] * self.U).transpose(0, 1)\n",
    "                v_grad[:, negatives] += ((neg_mask * ranking_weight)[:, None] * self.U).transpose(0, 1)\n",
    "            self.U -= lr * u_grad / acc_grad\n",
    "            self.V -= lr * v_grad / acc_grad\n",
    "            mean_delta /= acc_grad\n",
    "            t.set_postfix_str(f\"Avg delta: {mean_delta:4f} | Avg nabla V: {v_grad.abs().mean():.4f} | L2 Norm: {(self.U**2).mean():.4f}\")\n",
    "        self._build_trees()\n",
    "\n",
    "warp = WARP(u_users, u_movies, 64)\n",
    "warp.fit(u2p, u2n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 4.,  ..., 0., 0., 0.],\n",
       "        [4., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_ratings_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0010, -0.0744, -0.0742,  ..., -0.0762, -0.0762, -0.0770],\n",
       "        [-0.0031, -0.0592, -0.0586,  ..., -0.0601, -0.0594, -0.0593],\n",
       "        [-0.0087, -0.0174, -0.0175,  ..., -0.0177, -0.0180, -0.0175],\n",
       "        ...,\n",
       "        [-0.0074,  0.0329,  0.0295,  ...,  0.0304,  0.0289,  0.0308],\n",
       "        [-0.0139,  0.0315,  0.0311,  ...,  0.0297,  0.0302,  0.0297],\n",
       "        [-0.0030, -0.0512, -0.0511,  ..., -0.0510, -0.0506, -0.0513]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1959    Saving Private Ryan (1998)',\n",
       " '3634    Mad Max 2 (a.k.a. The Road Warrior) (1981)',\n",
       " '1029    That Thing You Do! (1996)',\n",
       " '257    Star Wars: Episode IV - A New Hope (1977)',\n",
       " '1180    Raiders of the Lost Ark (1981)',\n",
       " '1267    Ben-Hur (1959)',\n",
       " \"3197    Man Bites Dog (C'est arriv� pr�s de chez vous)...\",\n",
       " '3047    Miss Julie (1999)',\n",
       " '1358    Young Guns II (1990)',\n",
       " '1208    Quiet Man, The (1952)',\n",
       " '3439    Outlaw Josey Wales, The (1976)',\n",
       " '1023    Die Hard (1988)',\n",
       " '2882    Fistful of Dollars, A (1964)',\n",
       " '147    Amateur (1994)',\n",
       " '108    Braveheart (1995)',\n",
       " '73    Bed of Roses (1996)',\n",
       " '1885    Rocky (1976)',\n",
       " '1183    Good, The Bad and The Ugly, The (1966)',\n",
       " '1366    Jaws (1975)',\n",
       " '2807    Thumbelina (1994)']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(4, warp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0    Toy Story (1995)',\n",
       " '1308    Amityville Curse, The (1990)',\n",
       " '1445    Best Men (1997)',\n",
       " '3275    Blood Feast (1963)',\n",
       " '873    Bogus (1996)',\n",
       " '1542    Simple Wish, A (1997)',\n",
       " '3323    She-Devil (1989)',\n",
       " '2980    How I Won the War (1967)',\n",
       " '435    Dangerous Game (1993)',\n",
       " '65    Lawnmower Man 2: Beyond Cyberspace (1996)',\n",
       " '2417    24-hour Woman (1998)',\n",
       " '241    Gumby: The Movie (1995)',\n",
       " '288    Poison Ivy II (1995)',\n",
       " '3040    River, The (1984)',\n",
       " '3097    Brenda Starr (1989)',\n",
       " \"678    It's My Party (1995)\",\n",
       " '867    Bye-Bye (1995)',\n",
       " '2062    Autumn Sonata (H�stsonaten ) (1978)',\n",
       " '658    Faithful (1996)',\n",
       " '3313    Song of Freedom (1936)']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similars(1, warp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
