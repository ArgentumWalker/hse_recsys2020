{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Матричные факторизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной работе вам предстоит познакомиться с практической стороной матричных разложений.\n",
    "Работа поделена на 4 задания:\n",
    "1. Вам необходимо реализовать SVD разложения используя SGD на explicit данных\n",
    "2. Вам необходимо реализовать матричное разложения используя ALS на implicit данных\n",
    "3. Вам необходимо реализовать матричное разложения используя BPR(pair-wise loss) на implicit данных\n",
    "4. Вам необходимо реализовать матричное разложения используя WARP(list-wise loss) на implicit данных\n",
    "\n",
    "Мягкий дедлайн 28 Сентября (пишутся замечания, выставляется оценка, есть возможность исправить до жесткого дедлайна)\n",
    "\n",
    "Жесткий дедлайн 5 Октября (Итоговая проверка)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from lightfm.datasets import fetch_movielens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной работе мы будем работать с explicit датасетом movieLens, в котором представленны пары user_id movie_id и rating выставленный пользователем фильму\n",
    "\n",
    "Скачать датасет можно по ссылке https://grouplens.org/datasets/movielens/1m/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ml-1m/ratings.dat', delimiter='::', header=None, \n",
    "        names=['user_id', 'movie_id', 'rating', 'timestamp'], \n",
    "        usecols=['user_id', 'movie_id', 'rating'], engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_info = pd.read_csv('ml-1m/movies.dat', delimiter='::', header=None, \n",
    "        names=['movie_id', 'name', 'category'], engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicit данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1197</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2804</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating\n",
       "0        1      1193       5\n",
       "1        1       661       3\n",
       "2        1       914       3\n",
       "3        1      3408       4\n",
       "4        1      2355       5\n",
       "5        1      1197       3\n",
       "6        1      1287       5\n",
       "7        1      2804       5\n",
       "8        1       594       4\n",
       "9        1       919       4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы преобразовать текущий датасет в Implicit, давайте считать что позитивная оценка это оценка >=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "implicit_ratings = ratings.loc[(ratings['rating'] >= 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2804</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>595</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>938</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2398</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  movie_id  rating\n",
       "0         1      1193       5\n",
       "3         1      3408       4\n",
       "4         1      2355       5\n",
       "6         1      1287       5\n",
       "7         1      2804       5\n",
       "8         1       594       4\n",
       "9         1       919       4\n",
       "10        1       595       5\n",
       "11        1       938       4\n",
       "12        1      2398       4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit_ratings.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удобнее работать с sparse матричками, давайте преобразуем DataFrame в CSR матрицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = implicit_ratings[\"user_id\"]\n",
    "movies = implicit_ratings[\"movie_id\"]\n",
    "user_item = sp.coo_matrix((np.ones_like(users), (users, movies)))\n",
    "user_item_t_csr = user_item.T.tocsr()\n",
    "user_item_csr = user_item.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве примера воспользуемся ALS разложением из библиотеки implicit\n",
    "\n",
    "Зададим размерность латентного пространства равным 64, это же определяет размер user/item эмбедингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    }
   ],
   "source": [
    "model = implicit.als.AlternatingLeastSquares(factors=64, iterations=100, calculate_training_loss=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве loss здесь всеми любимый RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e26d25210a14c9aaad6163d5b5d80bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(user_item_t_csr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим похожие фильмы по 1 movie_id = Истории игрушек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                name                      category\n",
       "0         1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1         2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2         3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3         4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4         5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_info.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similars = lambda item_id, model : [movie_info[movie_info[\"movie_id\"] == x[0]][\"name\"].to_string() \n",
    "                                        for x in model.similar_items(item_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, симилары действительно оказались симиларами.\n",
    "\n",
    "Качество симиларов часто является хорошим способом проверить качество алгоритмов.\n",
    "\n",
    "P.S. Если хочется поглубже разобраться в том как разные алгоритмы формируют разные латентные пространства, рекомендую загружать полученные вектора в tensorBoard и смотреть на сформированное пространство"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0    Toy Story (1995)',\n",
       " '3045    Toy Story 2 (1999)',\n",
       " \"2286    Bug's Life, A (1998)\",\n",
       " '33    Babe (1995)',\n",
       " '2315    Babe: Pig in the City (1998)',\n",
       " '584    Aladdin (1992)',\n",
       " '1526    Hercules (1997)',\n",
       " '3817    Went to Coney Island on a Mission From God... ...',\n",
       " '2252    Pleasantville (1998)',\n",
       " '2692    Iron Giant, The (1999)']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similars(1, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте теперь построим рекомендации для юзеров\n",
    "\n",
    "Как мы видим юзеру нравится фантастика, значит и в рекомендациях ожидаем увидеть фантастику"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_user_history = lambda user_id, implicit_ratings : [movie_info[movie_info[\"movie_id\"] == x][\"name\"].to_string() \n",
    "                                            for x in implicit_ratings[implicit_ratings[\"user_id\"] == user_id][\"movie_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3399    Hustler, The (1961)',\n",
       " '2882    Fistful of Dollars, A (1964)',\n",
       " '1196    Alien (1979)',\n",
       " '1023    Die Hard (1988)',\n",
       " '257    Star Wars: Episode IV - A New Hope (1977)',\n",
       " '1959    Saving Private Ryan (1998)',\n",
       " '476    Jurassic Park (1993)',\n",
       " '1180    Raiders of the Lost Ark (1981)',\n",
       " '1885    Rocky (1976)',\n",
       " '1081    E.T. the Extra-Terrestrial (1982)',\n",
       " '3349    Thelma & Louise (1991)',\n",
       " '3633    Mad Max (1979)',\n",
       " '2297    King Kong (1933)',\n",
       " '1366    Jaws (1975)',\n",
       " '1183    Good, The Bad and The Ugly, The (1966)',\n",
       " '2623    Run Lola Run (Lola rennt) (1998)',\n",
       " '2878    Goldfinger (1964)',\n",
       " '1220    Terminator, The (1984)']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_user_history(4, implicit_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось! \n",
    "\n",
    "Мы действительно порекомендовали пользователю фантастику и боевики, более того встречаются продолжения тех фильмов, которые он высоко оценил"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations = lambda user_id, model : [movie_info[movie_info[\"movie_id\"] == x[0]][\"name\"].to_string() \n",
    "                                               for x in model.recommend(user_id, user_item_csr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['585    Terminator 2: Judgment Day (1991)',\n",
       " '1271    Indiana Jones and the Last Crusade (1989)',\n",
       " '1182    Aliens (1986)',\n",
       " '1284    Butch Cassidy and the Sundance Kid (1969)',\n",
       " '1178    Star Wars: Episode V - The Empire Strikes Back...',\n",
       " '2502    Matrix, The (1999)',\n",
       " '3402    Close Encounters of the Third Kind (1977)',\n",
       " '847    Godfather, The (1972)',\n",
       " '3458    Predator (1987)',\n",
       " '2460    Planet of the Apes (1968)']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(4, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь ваша очередь реализовать самые популярные алгоритмы матричных разложений\n",
    "\n",
    "Что будет оцениваться:\n",
    "1. Корректность алгоритма\n",
    "2. Качество получившихся симиларов\n",
    "3. Качество итоговых рекомендаций для юзера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from sklearn.neighbors import KDTree \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1. Не использую готовые решения, реализовать SVD разложение используя SGD на explicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratings_to_tensor(ratings, unique_users=None, unique_movies=None):\n",
    "    if unique_users is None:\n",
    "        unique_users = ratings.user_id.unique()\n",
    "    if unique_movies is None:\n",
    "        unique_movies = ratings.movie_id.unique()\n",
    "    user2id = dict([(u, i) for i, u in enumerate(unique_users)])\n",
    "    movie2id = dict([(m, i) for i, m in enumerate(unique_movies)])\n",
    "    mask = torch.zeros(len(unique_users), len(unique_movies))\n",
    "    mat = torch.zeros(len(unique_users), len(unique_movies))\n",
    "    for u, m, r in zip(ratings.user_id, ratings.movie_id, ratings.rating):\n",
    "        mat[user2id[u]][movie2id[m]] = float(r)\n",
    "        mask[user2id[u]][movie2id[m]] = 1\n",
    "    mask = mask.bool()\n",
    "    return mat, mask, unique_users, unique_movies\n",
    "\n",
    "ratings_tensor, rt_mask, u_users, u_movies = ratings_to_tensor(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 3., 3.,  ..., 0., 0., 0.],\n",
       "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 3., 4.,  ..., 0., 0., 0.],\n",
       "        [4., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecSys:\n",
    "    def __init__(self, users, items):\n",
    "        self.user2id = dict([(u, i) for i, u in enumerate(users)])\n",
    "        self.item2id = dict([(m, i) for i, m in enumerate(items)])\n",
    "        self.users = users\n",
    "        self.items = items\n",
    "        self.items_tree = None\n",
    "        \n",
    "    def get_items_repr(self):\n",
    "        raise NotImplemented\n",
    "    \n",
    "    def compute_score(self):\n",
    "        raise NotImplemented\n",
    "        \n",
    "    def _build_trees(self):\n",
    "        self.items_tree = KDTree(self.get_items_repr())\n",
    "    \n",
    "    def recommend(self, user_id, _, k=20):\n",
    "        u = self.user2id[user_id]\n",
    "        r = self.compute_score()[u]\n",
    "        idx = list(reversed(np.argsort(r)))[:k]\n",
    "        result_idx = [self.items[i] for i in idx]\n",
    "        return list(zip(result_idx, r[idx]))\n",
    "        \n",
    "    def similar_items(self, item_id, k=20):\n",
    "        i = [self.get_items_repr()[self.item2id[item_id]]]\n",
    "        d, idx = self.items_tree.query(i, k, return_distance=True)\n",
    "        true_idx = [self.items[i] for i in idx[0]]\n",
    "        return list(zip(true_idx, d[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e86711cb784132963f4c4871d6814a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class SVD(RecSys):\n",
    "    def __init__(self, users, items, hidden_size=64):\n",
    "        super().__init__(users, items)\n",
    "        self.U = torch.rand(len(users), hidden_size) / hidden_size**0.5\n",
    "        self.V = torch.rand(hidden_size, len(items)) / hidden_size**0.5\n",
    "        \n",
    "    def __call__(self):\n",
    "        return self.U.matmul(self.V)\n",
    "    \n",
    "    def get_items_repr(self):\n",
    "        return self.V.transpose(0, 1).cpu().numpy()\n",
    "    \n",
    "    def compute_score(self):\n",
    "        return self().cpu().numpy()\n",
    "\n",
    "    def fit(self, x, x_mask, iterations=500, lr=100.0, weight_decay=1e-2, masked=False):\n",
    "        # It can be done way more effectively with good dataloader, batches and torch.optim, \n",
    "        # but ready solutions are forbidden :(\n",
    "        t = tqdm(range(iterations))\n",
    "        ratings_count = x_mask.int().sum().item()\n",
    "        u_count = torch.ones_like(self.U).sum() # Well, this is obviously not optimal\n",
    "        v_count = torch.ones_like(self.V).sum()\n",
    "        for i in t:\n",
    "            eps = (self() - x)\n",
    "            eps[x_mask.logical_not()] = 0 # Do not update over NaN items\n",
    "            u_grad = eps.matmul(self.V.transpose(0, 1)) / ratings_count + weight_decay * self.U / u_count\n",
    "            v_grad = self.U.transpose(0, 1).matmul(eps) / ratings_count + weight_decay * self.V / v_count\n",
    "            self.U -= lr * u_grad\n",
    "            self.V -= lr * v_grad\n",
    "            mse = ((self() - x) ** 2)[x_mask].sum() / ratings_count\n",
    "            t.set_postfix_str(f\"MSE: {mse:.4f} | L2 Norm: {(self.U**2).mean():.4f}\")\n",
    "        self._build_trees()\n",
    "\n",
    "svd = SVD(u_users, u_movies, 64)\n",
    "svd.fit(ratings_tensor, rt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 3., 3.,  ..., 0., 0., 0.],\n",
       "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 3., 4.,  ..., 0., 0., 0.],\n",
       "        [4., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.5910, 3.6594, 4.3366,  ..., 0.8262, 1.2549, 1.3526],\n",
       "        [4.1528, 3.2706, 4.0347,  ..., 0.7396, 1.1527, 1.2397],\n",
       "        [4.5018, 3.4541, 4.3040,  ..., 0.7892, 1.2092, 1.3049],\n",
       "        ...,\n",
       "        [4.1187, 3.2485, 3.9589,  ..., 0.7326, 1.1438, 1.1962],\n",
       "        [4.3108, 3.3682, 4.0602,  ..., 0.7299, 1.1456, 1.2159],\n",
       "        [4.2949, 3.4033, 3.7430,  ..., 0.6696, 1.0649, 1.1771]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2836    Sanjuro (1962)',\n",
       " '847    Godfather, The (1972)',\n",
       " '1132    Wrong Trousers, The (1993)',\n",
       " '1950    Seven Samurai (The Magnificent Seven) (Shichin...',\n",
       " '1162    Paths of Glory (1957)',\n",
       " '900    Casablanca (1942)',\n",
       " '1189    To Kill a Mockingbird (1962)',\n",
       " \"523    Schindler's List (1993)\",\n",
       " '49    Usual Suspects, The (1995)',\n",
       " '892    Rear Window (1954)',\n",
       " '735    Close Shave, A (1995)',\n",
       " '315    Shawshank Redemption, The (1994)',\n",
       " '910    Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)',\n",
       " '2953    General, The (1927)',\n",
       " '1230    Bridge on the River Kwai, The (1957)',\n",
       " \"1176    One Flew Over the Cuckoo's Nest (1975)\",\n",
       " '2961    Yojimbo (1961)',\n",
       " '1186    Lawrence of Arabia (1962)',\n",
       " '740    Dr. Strangelove or: How I Learned to Stop Worr...',\n",
       " '1242    Great Escape, The (1963)']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(4, svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0    Toy Story (1995)',\n",
       " '3045    Toy Story 2 (1999)',\n",
       " \"2286    Bug's Life, A (1998)\",\n",
       " '584    Aladdin (1992)',\n",
       " '591    Beauty and the Beast (1991)',\n",
       " '360    Lion King, The (1994)',\n",
       " '1222    Glory (1989)',\n",
       " '2012    Little Mermaid, The (1989)',\n",
       " '33    Babe (1995)',\n",
       " '2338    Cocoon (1985)',\n",
       " '1282    Field of Dreams (1989)',\n",
       " '942    Mr. Smith Goes to Washington (1939)',\n",
       " '2009    Jungle Book, The (1967)',\n",
       " '436    Dave (1993)',\n",
       " '1016    Dumbo (1941)',\n",
       " '907    Wizard of Oz, The (1939)',\n",
       " '3294    American Graffiti (1973)',\n",
       " '148    Apollo 13 (1995)',\n",
       " \"890    Breakfast at Tiffany's (1961)\",\n",
       " '1421    Kolya (1996)']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similars(1, svd)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2. Не использую готовые решения, реализовать матричное разложение используя ALS на implicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_ratings_tensor, i_rt_mask, _, _ = ratings_to_tensor(implicit_ratings, u_users, u_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5482a110a0b4c3daa01c921ef21d63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class ALS(RecSys):\n",
    "    def __init__(self, users, items, hidden_size=64):\n",
    "        super().__init__(users, items)\n",
    "        self.U = torch.rand(len(users), hidden_size) / hidden_size**0.5\n",
    "        self.V = torch.rand(hidden_size, len(items)) / hidden_size**0.5\n",
    "        self.v_bias = torch.zeros(len(items))\n",
    "        self.u_bias = torch.zeros(len(users))\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "    def __call__(self):\n",
    "        return self.U.matmul(self.V)\n",
    "    \n",
    "    def get_items_repr(self):\n",
    "        return self.V.transpose(0, 1).cpu().numpy()\n",
    "    \n",
    "    def compute_score(self):\n",
    "        return self().cpu().numpy()\n",
    "\n",
    "    def fit(self, x, x_mask, iterations=8, nonzero_coef=10, weight_decay=0.01):\n",
    "        t = tqdm(range(iterations))\n",
    "        ratings_count = x_mask.int().sum().item() \n",
    "        u_count = torch.ones_like(self.U).sum() # Well, this is obviously not optimal\n",
    "        v_count = torch.ones_like(self.V).sum()\n",
    "        x = x.clone()\n",
    "        x[x_mask] = 1\n",
    "        w = torch.ones_like(x)\n",
    "        w[x_mask] += nonzero_coef * x[x_mask].abs()\n",
    "        w /= w.max()\n",
    "        x_target = w * x\n",
    "        for _ in t:\n",
    "            # Step 1: User representations\n",
    "            for u in range(len(self.U)):\n",
    "                Vb = torch.cat([self.V, torch.ones(1, self.V.size(1))], dim=0) # Add ones to include bias\n",
    "                VCV = Vb.matmul(w[u][:, None] * Vb.transpose(0, 1))\n",
    "                VCV = VCV + weight_decay * torch.eye(self.hidden_size + 1)\n",
    "                VCV = torch.inverse(VCV)\n",
    "                Ub = VCV.matmul(Vb).matmul((w[u] * (x[u] - self.v_bias)))\n",
    "                self.U[u] = Ub[:-1]\n",
    "                self.u_bias[u] = Ub[-1]\n",
    "            # Step 2: Item representations\n",
    "            for i in range(self.V.size(1)):\n",
    "                Ub  = torch.cat([self.U, torch.ones(self.U.size(0), 1)], dim=1) # Add ones to include bias\n",
    "                UCU = Ub.transpose(0, 1).matmul(w[:, i][:, None] * Ub)\n",
    "                UCU = UCU + weight_decay * torch.eye(self.hidden_size + 1)\n",
    "                UCU = torch.inverse(UCU)\n",
    "                Vb = UCU.matmul(Ub.transpose(0, 1)).matmul((w[:, i] * (x[:, i] - self.u_bias)))\n",
    "                self.V[:, i] = Vb[:-1]\n",
    "                self.v_bias[i] = Vb[-1]\n",
    "            # Log\n",
    "            uv = self()\n",
    "            mse = ((uv + self.u_bias[:, None].expand_as(uv)  + self.v_bias[None, :].expand_as(uv) - x) ** 2)[x_mask].sum() / ratings_count\n",
    "            t.set_postfix_str(f\"MSE: {mse:.4f} | L2 Norm: {(self.U**2).mean():.4f}\")\n",
    "        self._build_trees()\n",
    "\n",
    "als = ALS(u_users, u_movies, 64)\n",
    "als.fit(i_ratings_tensor, i_rt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 4.,  ..., 0., 0., 0.],\n",
       "        [4., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_ratings_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0962,  0.1967,  0.0529,  ..., -0.2900, -0.2619, -0.3078],\n",
       "        [ 0.3977, -0.2376,  0.0501,  ..., -0.2349, -0.2373, -0.2313],\n",
       "        [-0.1559, -0.3170, -0.2624,  ..., -0.0858, -0.0743, -0.0843],\n",
       "        ...,\n",
       "        [-0.1803, -0.3090,  0.0109,  ..., -0.1518, -0.1719, -0.1570],\n",
       "        [-0.0149,  0.4103,  0.9205,  ...,  0.0949,  0.0782,  0.0629],\n",
       "        [ 0.5793,  0.1374,  0.3465,  ...,  0.0140, -0.0116,  0.0244]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1183    Good, The Bad and The Ugly, The (1966)',\n",
       " '1366    Jaws (1975)',\n",
       " '1220    Terminator, The (1984)',\n",
       " '2878    Goldfinger (1964)',\n",
       " '1196    Alien (1979)',\n",
       " '1885    Rocky (1976)',\n",
       " '1023    Die Hard (1988)',\n",
       " '585    Terminator 2: Judgment Day (1991)',\n",
       " '1182    Aliens (1986)',\n",
       " '453    Fugitive, The (1993)',\n",
       " '2882    Fistful of Dollars, A (1964)',\n",
       " '1267    Ben-Hur (1959)',\n",
       " '3349    Thelma & Louise (1991)',\n",
       " '1271    Indiana Jones and the Last Crusade (1989)',\n",
       " '2502    Matrix, The (1999)',\n",
       " '3633    Mad Max (1979)',\n",
       " '1284    Butch Cassidy and the Sundance Kid (1969)',\n",
       " '2875    Dirty Dozen, The (1967)',\n",
       " '2297    King Kong (1933)',\n",
       " '1180    Raiders of the Lost Ark (1981)']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(4, als)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0    Toy Story (1995)',\n",
       " '3045    Toy Story 2 (1999)',\n",
       " '1245    Groundhog Day (1993)',\n",
       " \"2286    Bug's Life, A (1998)\",\n",
       " '584    Aladdin (1992)',\n",
       " '33    Babe (1995)',\n",
       " '2252    Pleasantville (1998)',\n",
       " '2327    Shakespeare in Love (1998)',\n",
       " \"1854    There's Something About Mary (1998)\",\n",
       " '1596    Indian Summer (a.k.a. Alive & Kicking) (1996)',\n",
       " '990    Extreme Measures (1996)',\n",
       " '217    Cure, The (1995)',\n",
       " '634    Girl 6 (1996)',\n",
       " '2087    Best Man, The (Il Testimone dello sposo) (1997)',\n",
       " '1445    Best Men (1997)',\n",
       " '26    Now and Then (1995)',\n",
       " '355    I Like It Like That (1994)',\n",
       " '1938    Polish Wedding (1998)',\n",
       " '360    Lion King, The (1994)',\n",
       " '3092    Onegin (1999)']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similars(1, als)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3. Не использую готовые решения, реализовать матричное разложение BPR на implicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f41d68d6df64cdeb0fb1f88ee67c9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6040.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-9dacc2bb0e6c>:5: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  user2positives.append((x[u] != 0).nonzero().view(-1).tolist())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def build_positives_and_negatives(x):\n",
    "    user2positives = []\n",
    "    user2negatives = []\n",
    "    for u in tqdm(range(len(x))):\n",
    "        user2positives.append((x[u] != 0).nonzero().view(-1).tolist())\n",
    "        user2negatives.append((x[u] == 0).nonzero().view(-1).tolist())\n",
    "    return user2positives, user2negatives\n",
    "\n",
    "u2p, u2n = build_positives_and_negatives(i_rt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "659639635d9b43a8861aadfd4015b456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class BPR(RecSys):\n",
    "    def __init__(self, users, items, hidden_size=64):\n",
    "        super().__init__(users, items)\n",
    "        self.U = torch.rand(len(users), hidden_size) / hidden_size**0.5\n",
    "        self.V = torch.rand(hidden_size, len(items)) / hidden_size**0.5\n",
    "        \n",
    "    def __call__(self):\n",
    "        return self.U.matmul(self.V)\n",
    "    \n",
    "    def get_items_repr(self):\n",
    "        return self.V.transpose(0, 1).cpu().numpy()\n",
    "    \n",
    "    def compute_score(self):\n",
    "        return self().cpu().numpy()\n",
    "\n",
    "    def fit(self, user2positives, user2negatives, iterations=500, acc_grad=16, lr=0.1, weight_decay=1e-2, masked=False):\n",
    "        # It can be done way more effectively with good dataloader, batches and torch.optim, \n",
    "        # but ready solutions are forbidden :(\n",
    "        \n",
    "        t = tqdm(range(iterations))\n",
    "        for i in t:\n",
    "            u_grad = acc_grad * weight_decay * self.U\n",
    "            v_grad = acc_grad * weight_decay * self.V\n",
    "            mean_delta = 0.\n",
    "            x = self()\n",
    "            for _ in range(acc_grad):\n",
    "                # Build a batch\n",
    "                positives = []\n",
    "                negatives = []\n",
    "                pos_mask = []\n",
    "                neg_mask = []\n",
    "                for u in range(len(user2positives)):\n",
    "                    if len(user2positives[u]) != 0:\n",
    "                        pos_mask.append(1)\n",
    "                        positives.append(user2positives[u][random.randint(0, len(user2positives[u]) - 1)])\n",
    "                    else:\n",
    "                        pos_mask.append(0)\n",
    "                        positives.append(0)\n",
    "                    if len(user2negatives[u]) != 0:\n",
    "                        neg_mask.append(1)\n",
    "                        negatives.append(user2negatives[u][random.randint(0, len(user2negatives[u]) - 1)])\n",
    "                    else:\n",
    "                        neg_mask.append(0)\n",
    "                        negatives.append(0)\n",
    "                positives = torch.tensor(positives)\n",
    "                negatives = torch.tensor(negatives)\n",
    "                pos_mask = torch.tensor(pos_mask).float()\n",
    "                neg_mask = torch.tensor(neg_mask).float()\n",
    "\n",
    "                # Compute gradient\n",
    "                delta = x.gather(1, positives.unsqueeze(1)) - x.gather(1, negatives.unsqueeze(1)) \n",
    "                mean_delta += delta.mean()\n",
    "                delta = torch.exp(-delta).view(-1)\n",
    "                delta = -delta / (1 + delta)\n",
    "                v_positives = self.V[:, positives].transpose(0, 1)\n",
    "                v_negatives = self.V[:, negatives].transpose(0, 1)\n",
    "                u_grad += delta[:, None] * (pos_mask[:, None] * v_positives - neg_mask[:, None] * v_negatives)\n",
    "\n",
    "                v_grad[:, positives] += ((pos_mask * delta)[:, None] * self.U).transpose(0, 1)\n",
    "                v_grad[:, negatives] -= ((neg_mask * delta)[:, None] * self.U).transpose(0, 1)\n",
    "            self.U -= lr * u_grad / acc_grad\n",
    "            self.V -= lr * v_grad / acc_grad\n",
    "            mean_delta /= acc_grad\n",
    "            t.set_postfix_str(f\"Avg delta: {mean_delta:4f} | Avg nabla V: {v_grad.abs().mean():.4f} | L2 Norm: {(self.U**2).mean():.4f}\")\n",
    "        self._build_trees()\n",
    "\n",
    "bpr = BPR(u_users, u_movies, 64)\n",
    "bpr.fit(u2p, u2n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 4.,  ..., 0., 0., 0.],\n",
       "        [4., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_ratings_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-17.4593, -16.5712, -15.7135,  ..., -19.7635, -19.6285, -19.8437],\n",
       "        [-17.2175, -19.1786, -17.7831,  ..., -20.1193, -20.0580, -20.2460],\n",
       "        [-18.8126, -18.2768, -18.2640,  ..., -20.1706, -20.0336, -20.2300],\n",
       "        ...,\n",
       "        [-13.0497, -12.3906, -10.8588,  ..., -14.3123, -14.3344, -14.3234],\n",
       "        [-14.4118, -14.1217, -12.2789,  ..., -16.8662, -16.8537, -16.8588],\n",
       "        [-14.1867, -15.7780, -15.7144,  ..., -17.1913, -17.2094, -17.0888]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['257    Star Wars: Episode IV - A New Hope (1977)',\n",
       " '1196    Alien (1979)',\n",
       " '2878    Goldfinger (1964)',\n",
       " '1366    Jaws (1975)',\n",
       " '2879    From Russia with Love (1963)',\n",
       " '1885    Rocky (1976)',\n",
       " '1178    Star Wars: Episode V - The Empire Strikes Back...',\n",
       " '1220    Terminator, The (1984)',\n",
       " '1023    Die Hard (1988)',\n",
       " '1183    Good, The Bad and The Ugly, The (1966)',\n",
       " '585    Terminator 2: Judgment Day (1991)',\n",
       " '2882    Fistful of Dollars, A (1964)',\n",
       " '1180    Raiders of the Lost Ark (1981)',\n",
       " '2297    King Kong (1933)',\n",
       " '1182    Aliens (1986)',\n",
       " '1267    Ben-Hur (1959)',\n",
       " '2875    Dirty Dozen, The (1967)',\n",
       " '847    Godfather, The (1972)',\n",
       " '2847    Total Recall (1990)',\n",
       " '2993    Longest Day, The (1962)']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(4, bpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0    Toy Story (1995)',\n",
       " '2225    Antz (1998)',\n",
       " '584    Aladdin (1992)',\n",
       " '1005    That Darn Cat! (1965)',\n",
       " '33    Babe (1995)',\n",
       " '1850    Madeline (1998)',\n",
       " '2067    Nutty Professor, The (1963)',\n",
       " '463    Live Nude Girls (1995)',\n",
       " '2285    Rugrats Movie, The (1998)',\n",
       " '565    Little Big League (1994)',\n",
       " '1245    Groundhog Day (1993)',\n",
       " '1433    That Darn Cat! (1997)',\n",
       " '1664    Mouse Hunt (1997)',\n",
       " '1445    Best Men (1997)',\n",
       " '3327    Muppet Movie, The (1979)',\n",
       " '2759    Dudley Do-Right (1999)',\n",
       " '2315    Babe: Pig in the City (1998)',\n",
       " '2082    Gods Must Be Crazy II, The (1989)',\n",
       " '179    Mighty Morphin Power Rangers: The Movie (1995)',\n",
       " '1586    MatchMaker, The (1997)']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similars(1, bpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4. Не использую готовые решения, реализовать матричное разложение WARP на implicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657b7d90c5f24a968141c41b105f3ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class WARP(RecSys):\n",
    "    def __init__(self, users, items, hidden_size=64):\n",
    "        super().__init__(users, items)\n",
    "        self.U = torch.rand(len(users), hidden_size) / hidden_size**0.5\n",
    "        self.V = torch.rand(hidden_size, len(items)) / hidden_size**0.5\n",
    "        \n",
    "    def __call__(self):\n",
    "        return self.U.matmul(self.V)\n",
    "    \n",
    "    def get_items_repr(self):\n",
    "        return self.V.transpose(0, 1).cpu().numpy()\n",
    "    \n",
    "    def compute_score(self):\n",
    "        return self().cpu().numpy()\n",
    "\n",
    "    def fit(self, user2positives, user2negatives, iterations=200, samples=32, acc_grad=8, \n",
    "            lr=0.1, weight_decay=1e-2, margin=1.0):\n",
    "        # It can be done way more effectively with good dataloader, batches and torch.optim, \n",
    "        # but ready solutions are forbidden :(\n",
    "        \n",
    "        t = tqdm(range(iterations))\n",
    "        for i in t:\n",
    "            u_grad = acc_grad * weight_decay * self.U\n",
    "            v_grad = acc_grad * weight_decay * self.V\n",
    "            mean_delta = 0.\n",
    "            x = self()\n",
    "            for k in range(acc_grad):\n",
    "                # Build a batch\n",
    "                positives = []\n",
    "                negatives = []\n",
    "                ranking_weight = []\n",
    "                pos_mask = []\n",
    "                neg_mask = []\n",
    "                for u in range(len(user2positives)):\n",
    "                    if len(user2positives[u]) != 0:\n",
    "                        pos = user2positives[u][random.randint(0, len(user2positives[u]) - 1)]\n",
    "                        pos_mask.append(1)\n",
    "                        positives.append(pos)\n",
    "                        if len(user2negatives[u]) != 0:\n",
    "                            # Finding all high-ranked negatives is very slow, so we sample and estimate rank\n",
    "                            choosen_negatives = random.sample(user2negatives[u], min(samples, len(user2negatives[u])))\n",
    "                            bad_negatives = (x[u, choosen_negatives] > x[u, pos]).sum().item()\n",
    "                            neg_mask.append(1)\n",
    "                            neg = user2negatives[u][random.randint(0, len(user2negatives[u]) - 1)]\n",
    "                            negatives.append(neg)\n",
    "                            if x[u][pos] - x[u][neg] > margin:\n",
    "                                ranking_weight.append(0) # Margin condition\n",
    "                            else:\n",
    "                                ranking_weight.append(np.log(1 + len(user2negatives[u]) * bad_negatives / len(choosen_negatives)))\n",
    "                            #ranking_weight.append(np.log(1 + len(user2negatives[u]) * len(bad_negatives) / len(choosen_negatives)))\n",
    "                        \n",
    "                        else:\n",
    "                            neg_mask.append(0)\n",
    "                            negatives.append(0)\n",
    "                            ranking_weight.append(1)\n",
    "                    else:\n",
    "                        pos_mask.append(0)\n",
    "                        positives.append(0)\n",
    "                        neg_mask.append(1)\n",
    "                        ranking_weight.append(1)\n",
    "                        negatives.append(user2negatives[u][random.randint(0, len(user2negatives[u]) - 1)])\n",
    "\n",
    "                positives = torch.tensor(positives)\n",
    "                negatives = torch.tensor(negatives)\n",
    "                pos_mask = torch.tensor(pos_mask).float()\n",
    "                neg_mask = torch.tensor(neg_mask).float()\n",
    "                ranking_weight = torch.tensor(ranking_weight).float()\n",
    "                \n",
    "                # Compute gradient\n",
    "                mean_delta += (x.gather(1, positives.unsqueeze(1)) - x.gather(1, negatives.unsqueeze(1))).mean()\n",
    "                ranking_weight /= ranking_weight.max() # Fixing stability issues\n",
    "                v_positives = self.V[:, positives].transpose(0, 1)\n",
    "                v_negatives = self.V[:, negatives].transpose(0, 1)\n",
    "                u_grad += ranking_weight[:, None] * (neg_mask[:, None] * v_negatives - pos_mask[:, None] * v_positives)\n",
    "\n",
    "                v_grad[:, positives] -= ((pos_mask * ranking_weight)[:, None] * self.U).transpose(0, 1)\n",
    "                v_grad[:, negatives] += ((neg_mask * ranking_weight)[:, None] * self.U).transpose(0, 1)\n",
    "            self.U -= lr * u_grad / acc_grad\n",
    "            self.V -= lr * v_grad / acc_grad\n",
    "            mean_delta /= acc_grad\n",
    "            t.set_postfix_str(f\"Avg delta: {mean_delta:4f} | Avg nabla V: {v_grad.abs().mean():.4f} | L2 Norm: {(self.U**2).mean():.4f}\")\n",
    "        self._build_trees()\n",
    "\n",
    "warp = WARP(u_users, u_movies, 64)\n",
    "warp.fit(u2p, u2n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 4.,  ..., 0., 0., 0.],\n",
       "        [4., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_ratings_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.9726, -2.9980, -2.9918,  ..., -4.0777, -4.0973, -4.1130],\n",
       "        [-3.1142, -3.2395, -3.1724,  ..., -4.1884, -4.2435, -4.2195],\n",
       "        [-3.1944, -3.1547, -3.1560,  ..., -4.1085, -4.1201, -4.1381],\n",
       "        ...,\n",
       "        [-2.6185, -2.5534, -2.5495,  ..., -3.4222, -3.4874, -3.4432],\n",
       "        [-2.8896, -2.9676, -2.6774,  ..., -3.8913, -3.9428, -3.9211],\n",
       "        [-2.9340, -3.1158, -2.9771,  ..., -4.0965, -4.1410, -4.1111]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2878    Goldfinger (1964)',\n",
       " '1180    Raiders of the Lost Ark (1981)',\n",
       " '1885    Rocky (1976)',\n",
       " '588    Batman (1989)',\n",
       " '257    Star Wars: Episode IV - A New Hope (1977)',\n",
       " '2338    Cocoon (1985)',\n",
       " '2572    Superman II (1980)',\n",
       " '2588    Rocky Horror Picture Show, The (1975)',\n",
       " '2882    Fistful of Dollars, A (1964)',\n",
       " '1258    Young Frankenstein (1974)',\n",
       " '476    Jurassic Park (1993)',\n",
       " '2916    Robocop (1987)',\n",
       " '3458    Predator (1987)',\n",
       " '2332    Pale Rider (1985)',\n",
       " '1491    Fifth Element, The (1997)',\n",
       " '1284    Butch Cassidy and the Sundance Kid (1969)',\n",
       " '1355    Star Trek IV: The Voyage Home (1986)',\n",
       " '1192    Star Wars: Episode VI - Return of the Jedi (1983)',\n",
       " '3402    Close Encounters of the Third Kind (1977)',\n",
       " '928    Adventures of Robin Hood, The (1938)']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(4, warp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0    Toy Story (1995)',\n",
       " '1245    Groundhog Day (1993)',\n",
       " '3045    Toy Story 2 (1999)',\n",
       " '293    Pulp Fiction (1994)',\n",
       " \"2286    Bug's Life, A (1998)\",\n",
       " '1656    Good Will Hunting (1997)',\n",
       " '711    Wallace & Gromit: The Best of Aardman Animatio...',\n",
       " '2918    Who Framed Roger Rabbit? (1988)',\n",
       " '2255    Life Is Beautiful (La Vita � bella) (1997)',\n",
       " '604    Fargo (1996)',\n",
       " '3291    Hoosiers (1986)',\n",
       " \"523    Schindler's List (1993)\",\n",
       " '2991    Commitments, The (1991)',\n",
       " '1287    When Harry Met Sally... (1989)',\n",
       " '589    Silence of the Lambs, The (1991)',\n",
       " '1282    Field of Dreams (1989)',\n",
       " '3039    Fisher King, The (1991)',\n",
       " '2970    Trading Places (1983)',\n",
       " '1229    Nikita (La Femme Nikita) (1990)',\n",
       " '2199    Few Good Men, A (1992)']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similars(1, warp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
