{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import catboost\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 1, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort([3, 2, 1, 5])[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(path=\"data\"):\n",
    "    print(\"Preprocessing songs.csv ...\")\n",
    "    with open(path + \"/songs.csv\") as f:\n",
    "        first_readed = False\n",
    "        song2id = {}\n",
    "        artist_id2name = {}\n",
    "        artist2id = {}\n",
    "        composer2id = {}\n",
    "        lyrics2id = {}\n",
    "        song_id2data = {}\n",
    "        genre2id = {}\n",
    "        genre2ctn =[0 for _ in range(191)]\n",
    "        for i, l in enumerate(f):\n",
    "            if not first_readed:\n",
    "                first_readed = True\n",
    "                continue\n",
    "            parts = l[:-1].split(',')\n",
    "            song_id, song_length, genre_ids, artist_name, _, _, language = parts[:7]\n",
    "            if song_id not in song2id:\n",
    "                song2id[song_id] = len(song2id)\n",
    "                \n",
    "            if genre_ids == \"\":\n",
    "                genre_ids = []\n",
    "            else:\n",
    "                genre_ids = list(map(int, genre_ids.split(\"|\")))\n",
    "            for g in genre_ids:\n",
    "                if g not in genre2id:\n",
    "                    genre2id[g] = len(genre2id)\n",
    "                genre2ctn[genre2id[g]] += 1\n",
    "            genre_ids = [genre2id[g] for g in genre_ids]\n",
    "            if not artist_name in artist2id:\n",
    "                artist_id2name[len(artist2id)] = artist_name\n",
    "                artist2id[artist_name] = len(artist2id) \n",
    "                \n",
    "            song_id2data[song2id[song_id]] = [int(song_length), artist2id[artist_name], int(float(language)), genre_ids]\n",
    "        retain_genres = (np.argsort(genre2ctn)[::-1])[:10]\n",
    "        retain_genres = dict([(g, i) for i, g in enumerate(retain_genres)])\n",
    "        \n",
    "        for k in song_id2data:\n",
    "            genre_ids = song_id2data[k][-1]\n",
    "            genre_ids = [retain_genres[g] for g in genre_ids if g in retain_genres]\n",
    "            song_id2data[k][-1] = genre_ids\n",
    "        \n",
    "    print(\"Preprocessing members.csv ...\")\n",
    "    with open(path + \"/members.csv\", \"r\") as f:\n",
    "        first_readed = False\n",
    "        user2id = {}\n",
    "        member_id2data = {}\n",
    "        gender2id = {\"male\": -1, \"\": 0, \"female\": 1}\n",
    "        for l in f:\n",
    "            if not first_readed:\n",
    "                first_readed = True\n",
    "                continue\n",
    "            msno, city, bd, gender, registered_via, registration_init_time, expiration_date = l[:-1].split(',')\n",
    "            if msno not in user2id:\n",
    "                user2id[msno] = len(user2id)\n",
    "            member_id2data[user2id[msno]] = (\n",
    "                int(city), int(bd), gender2id[gender], int(registered_via), \n",
    "                int(registration_init_time), int(expiration_date)\n",
    "            )\n",
    "    print(\"Preprocessing train.csv ...\")\n",
    "    with open(path + \"/train.csv\", \"r\") as f:\n",
    "        first_readed = False\n",
    "        sst2id = {}\n",
    "        ssn2id = {}\n",
    "        st2id = {}\n",
    "        train = []\n",
    "        for l in f:\n",
    "            if not first_readed:\n",
    "                first_readed = True\n",
    "                continue\n",
    "            msno, song_id, source_system_tab, source_screen_name, source_type, target = l[:-1].split(',')\n",
    "            if msno not in user2id:\n",
    "                continue\n",
    "            if song_id not in song2id:\n",
    "                continue\n",
    "            if source_system_tab not in sst2id:\n",
    "                sst2id[source_system_tab] = len(sst2id)\n",
    "            if source_type not in st2id:\n",
    "                st2id[source_type] = len(st2id)\n",
    "            train.append((\n",
    "                user2id[msno], song2id[song_id], sst2id[source_system_tab], st2id[source_type], int(target)\n",
    "            ))\n",
    "    print(\"Total genres: \", len(genre2id))\n",
    "    print(\"Preprocessing song_extra_info.csv ...\")\n",
    "    with open(path + \"/song_extra_info.csv\") as f:\n",
    "        first_readed = False\n",
    "        song_id2name = {}\n",
    "        for l in f:\n",
    "            if not first_readed:\n",
    "                first_readed = True\n",
    "                continue\n",
    "            song_id, name, isrc = l[:-1].split(',')\n",
    "            \n",
    "            if song_id not in song2id:\n",
    "                continue\n",
    "            song_id2name[song2id[song_id]] = name\n",
    "            if song2id[song_id] in song_id2data:\n",
    "                song_id2data[song2id[song_id]].append(isrc)\n",
    "    return train, member_id2data, song_id2data, song_id2name, artist_id2name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing songs.csv ...\n",
      "Preprocessing members.csv ...\n",
      "Preprocessing train.csv ...\n",
      "Total genres:  191\n",
      "Preprocessing song_extra_info.csv ...\n"
     ]
    }
   ],
   "source": [
    "train, members, songs, song_id2name, artist_id2name = preprocess_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7377416"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isrc_to_year(isrc): # https://www.kaggle.com/kamilkk/i-have-to-say-this\n",
    "    if isrc != \"\":\n",
    "        if int(isrc[5:7]) > 17:\n",
    "            return 1900 + int(isrc[5:7])\n",
    "        else:\n",
    "            return 2000 + int(isrc[5:7])\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def one_hot_genres(genres):\n",
    "    result = [0 for _ in range(10)]\n",
    "    for g in genres:\n",
    "        result[g] = 1\n",
    "    return result\n",
    "    \n",
    "def get_song_features(song_id):\n",
    "    song_length, artist_id, language, genre_ids, isrc = songs[song_id]\n",
    "    year = isrc_to_year(isrc)\n",
    "    genre = one_hot_genres(genre_ids)\n",
    "    return [year, artist_id, language, song_length] + genre    \n",
    "\n",
    "def get_user_features(user_id):\n",
    "    return list(members[user_id])\n",
    "\n",
    "def extract_features(dataset):\n",
    "    X = []\n",
    "    y = []\n",
    "    for user_id, song_id, sst_id, st_id, tgt in dataset:\n",
    "        user_features = get_user_features(user_id)\n",
    "        song_features = get_song_features(song_id)\n",
    "        X.append(user_features + song_features + [])\n",
    "        y.append(tgt)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(train_function, parts=5):\n",
    "    train_shuffled = copy.deepcopy(train)\n",
    "    random.shuffle(train_shuffled)\n",
    "    X, y = extract_features(train_shuffled)\n",
    "    avg_stat = {}\n",
    "    for i in tqdm(range(parts)):\n",
    "        X_train = X[:i * len(train_shuffled) // parts] + X[(i+1) * len(train_shuffled) // parts:]\n",
    "        y_train = y[:i * len(train_shuffled) // parts] + y[(i+1) * len(train_shuffled) // parts:]\n",
    "        X_test = X[i * len(train_shuffled) // parts:(i+1) * len(train_shuffled) // parts]\n",
    "        y_test = y[i * len(train_shuffled) // parts:(i+1) * len(train_shuffled) // parts]\n",
    "        stat = train_function((X_train, y_train), (X_test, y_test))\n",
    "        for key in stat:\n",
    "            avg_stat[key] = avg_stat.get(key, 0) + stat[key] / parts\n",
    "    for key in avg_stat:\n",
    "        print(f\"{key}: {avg_stat[key]}\")\n",
    "    print()\n",
    "    return avg_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_catboost(train, test, verbose=False):\n",
    "    X_train, y_train = train\n",
    "    X_test, y_test = test\n",
    "    model = catboost.CatBoostClassifier(iterations=100, verbose=verbose, depth=16)\n",
    "    pool = catboost.Pool(X_train, y_train)\n",
    "    model.fit(pool)\n",
    "    pool = catboost.Pool(X_test, y_test)\n",
    "    metrics = model.eval_metrics(pool, ['Logloss', 'AUC'])\n",
    "    for k in metrics:\n",
    "        metrics[k] = metrics[k][-1]\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1bef1b7b0144c95aaf8a87a1aa5b00b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logloss: 0.6233986017294988\n",
      "AUC: 0.7078994217487762\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Logloss': 0.6233986017294988, 'AUC': 0.7078994217487762}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(train_catboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC AUC ~ 0.7 which is (maybe) good enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
